---
layout: post
title: "Academic related ^^"
date: 2018-10-06
---
# For those who are interested in my song lists, try [this](https://yjkweon24.github.io/blog/2018/10/23/songs-that-i-love)

<br>

<br>

## Statistics 
Statistics is fun!

Here are the [consumer analysis article](https://data.quora.com/A-Robust-Statistical-Test-for-Ratio-Metrics) co-written by one of my previous GSIs: Johnny and [2018 FIFA worldcup article](https://data.quora.com/FIFA-World-Cup-2018-seen-through-Quoras-numbers). 

This explains how stats can be applied into the real world problems! ^^

KL Divergence in Korean by Skywalk blog: [Link](https://hyunw.kim/blog/2017/10/27/KL_divergence.html)

<br>

## Bioinformatics
Review of Statistical Learning Methods in Integrated Omics Studies (An Integrated Information Science) by Irene Sui Lan Zeng and Thomas Lumley: [Paper](https://journals.sagepub.com/doi/pdf/10.1177/1177932218759292)

Dimension reduction techniques for the integrative analysis of multi-omics data by Chen Meng, et. al.: [Paper](https://academic.oup.com/bib/article/17/4/628/2240645)

Chapter 11: Genome-Wide Association Studies by William S. Bush and Jason H. Moore: [Paper](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002822)

Multi-Omics Factor Analysis—a framework for unsupervised integration of multi-omics data sets by Ricard Argelaguet et.al.:[Paper](https://www.embopress.org/doi/full/10.15252/msb.20178124)

DIABLO: an integrative approach for identifying key molecular drivers from multi-omic assays by Amrit Singh et.al.:[Paper](https://doi.org/10.1093/bioinformatics/bty1054)

Why do we use mice for many experiments? [link](https://www.livescience.com/32860-why-do-medical-researchers-use-mice.html)

About Electronic Health Care Records. [link](https://www.businessinsider.com/electronic-health-records-benefits-challenges)

Find mapping -> From genome-wide associations to candidate causal variants by statistical fine-mapping by Daniel J. Schaid et.al.: [Paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6050137/)

Make improvements in Electronic health records (EHR) -> High-fidelity phenotyping: richness and freedom from bias by George Hripcsak and David J Albers: [Paper](https://academic.oup.com/jamia/article/25/3/289/4484121?login=true)

Multi-scale inference ofo genetic trait architecture using biologically annotated neural networks by Pinar Demetci et.al.: [Paper](https://www.biorxiv.org/content/10.1101/2020.07.02.184465v2)

Deep Convolutional Neural Networks for Breast Cancer Histology Image Analysis by Alexander Rakhlin et.al.: [Paper](https://arxiv.org/abs/1802.00752)

A unified framework for cross-population trait prediction by leveraging the genetic correlation of polygenic traits by Mingxuan Cai et.al.: [Paper](https://doi.org/10.1016/j.ajhg.2021.03.002)

Inferring multimodal latent topics from electronic health records by Yue Li et.al.: [Paper](https://www.nature.com/articles/s41467-020-16378-3)

Going to Bat(s) for Studies of Disease Tolerance by Judith N Mandl et.al.: [Paper](https://www.frontiersin.org/articles/10.3389/fimmu.2018.02112/full) ~~ COVID 19 related???

Single-cell epigenomic analyses implicate candidate causal variants at inherited risk loci for Alzheimer’s and Parkinson’s diseases: [Paper](https://www.nature.com/articles/s41588-020-00721-x) ~~ Power of single cell analysis

Joint probabilistic modeling of single-cell multi-omic data with totalVI by Adam Gayoso et.al.: [Paper](https://www.nature.com/articles/s41592-020-01050-x) ~~ joint analysis of CITE seq data

<br>

## For Project on [MetaboAnalyst](https://www.metaboanalyst.ca/home.xhtml) - Metab (2021 Summer ~ )

Predicting Network Activity from High Throughput Metabolomics by Shuzhao Li et.al.: [Paper](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003123) ~ mummichog algorithm (using metabolic pathways and networks to predict functional acitivity without priori identifications of metabolites using biological activity) introduction with a few applications

MetaboAnalyst 4.0: towards more transparent and integrative metabolomics analysis by Jasmine Chong et.al.: [Paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6030889/) ~ update 1. R-command tracking+display and companion [metaboAnalystR](#mar) package, 2. MS peaks to pathways to predict pathway activity from untargeted MS using mummichog, 3. biomarker meta-analysis thru combination of multiple metabolomics data, and 4. network explorer for integrative analysis of metabolomics, metagenomics, transcriptomics

MetaboAnalyst 5.0: narrowing the gap between raw spectra and functional insights by Zhiqiang Pang et.al.: [Paper](https://academic.oup.com/nar/advance-article/doi/10.1093/nar/gkab382/6279832) ~ update 1. LC-MS spectra processing module (automated paramter optimization and resumable analysis) with interactive plots, 2. functional analysis module (select any peak groups of interests and evaluate enrichment of potential functions), and 3. functional meta-analysis module (combine multiple global metabolomics datasets) by pathway level integration (different samples) or pooling peaks (same samples)

Revealing disease-associated pathways by network integration of untargeted metabolomics by Leila Pirhaji et.al: [Paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5209295/)

[link](#mar)
<a name="mar">
MetaboAnalystR 2.0: From Raw Spectra to Biological Insights by Jasmine Chong et.al.: [Paper](https://www.mdpi.com/2218-1989/9/3/57) ~ update 1. raw spectral processing and 2. mummichog algorithm. Show two case studies

MetaboAnalystR 3.0: Toward an Optimized Workflow for Global Metabolomics by Zhiqiang Pang et.al.: [Paper](https://www.mdpi.com/2218-1989/10/5/186) ~ update 1. efficient parameter optimization, 2. automated batch effect correction, and 3. more accurate pathway activity prediction with retention time + updated pathway libraries => faster computationally and more biologically meaningful interpretations
</a>
  
<br>

## Machine Learning
Nice Intro-ANN, CNN, and RNN: [link](https://www.analyticsvidhya.com/blog/2020/02/cnn-vs-rnn-vs-mlp-analyzing-3-types-of-neural-networks-in-deep-learning/)

Love this BLOG-MachineCurve by Chris: [link](https://www.machinecurve.com/index.php/2019/07/18/can-neural-networks-approximate-mathematical-functions/)
<br/>[link1](https://www.machinecurve.com/index.php/2019/07/27/how-to-create-a-basic-mlp-classifier-with-the-keras-sequential-api/) -> MLP keras and tensorflow example
<br/>[link2](https://www.machinecurve.com/index.php/2018/12/07/convolutional-neural-networks-and-their-components-for-computer-vision/) -> CNN (Convolutional layers, pooling layers, fully connected layers)
<br/>[link3](https://www.machinecurve.com/index.php/2019/09/17/how-to-create-a-cnn-classifier-with-keras/) -> CNN keras and tensorflow example

towardsdatascience: [link](https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9) -> Here, specifically, it talks about **batch size v.s. epoch v.s. number of batches (iterations)***
<br/>[link1](https://towardsdatascience.com/deep-learnings-mathematics-f52b3c4d2576)&emsp;[link2](https://towardsdatascience.com/https-medium-com-piotr-skalski92-deep-dive-into-deep-networks-math-17660bc376ba) -> math behind Deep Learning step by step
<br/>[link3](https://towardsdatascience.com/recurrent-neural-networks-b7719b362c65) -> RNN
<br/>[link4](https://towardsdatascience.com/convolutional-neural-networks-mathematics-1beb3e6447c0) -> CNN

freeCodeCamp: [link](https://www.freecodecamp.org/news/connections-between-deep-learning-physics-and-pure-mathematics-part-i-947abeb3a5dd/) -> Here, specifically, it talks about the ***relationship between math and neural networks*** with an example

AnalyticsVidhya: [link](https://www.analyticsvidhya.com/blog/2020/01/fundamentals-deep-learning-activation-functions-when-to-use-them/#:~:text=The%20main%20advantage%20of%20using,neurons%20at%20the%20same%20time.&text=Due%20to%20this%20reason%2C%20during,neurons%20which%20never%20get%20activated.) -> Here, specifically, it talks about the **activation functions** for the layers.
<br/>[link1](https://www.analyticsvidhya.com/blog/2017/01/introduction-to-reinforcement-learning-implementation/) -> RL

Stanford Deep Learning CS 230: [link](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks) -> CNN and RNN (Super nice cheatsheets!!!)

Word2Vec by *The Coding Train*: [link](https://www.youtube.com/watch?v=mI23bDF0VRI&t=671s&ab_channel=TheCodingTrain)

Reinforcement Learning by **deepsense.ai** blog: [link](https://deepsense.ai/what-is-reinforcement-learning-the-complete-guide/)

Good summary of Reinforcement Learning by SmartLab AI: [link](https://medium.com/@SmartLabAI/reinforcement-learning-algorithms-an-intuitive-overview-904e2dff5bbc)

Self driving cab using RL by learndatasci: [link](https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/)

Pytorch Intro in Korean: [link](https://tutorials.pytorch.kr/beginner/deep_learning_60min_blitz.html) - original [link](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) 

Good explanation of logistic regression for classification problems by Christoph Molnar: [link](https://christophm.github.io/interpretable-ml-book/logistic.html)

Hyperparameters optimization for Deep Learning and Early Stopping criteria by flydhub blog: [link](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/) => **conclusion for Hyp. opt.: Bayes sequential model based optimization is the BEST for DL** 

Variational Autoencoder explanation by **Arxiv Insights**: [link](https://youtu.be/9zKuYvjFFS8)
