---
layout: post
title: "Academic related ^^"
date: 2018-10-06
---
# For those who are interested in my song lists, try [this](https://yjkweon24.github.io/blog/2018/10/23/songs-that-i-love)

<br>

<br>

## Statistics 
Statistics is fun!

Here are the [consumer analysis article](https://data.quora.com/A-Robust-Statistical-Test-for-Ratio-Metrics) co-written by one of my previous GSIs: Johnny and [2018 FIFA worldcup article](https://data.quora.com/FIFA-World-Cup-2018-seen-through-Quoras-numbers). 

This explains how stats can be applied into the real world problems! ^^

KL Divergence in Korean by Skywalk blog: [Link](https://hyunw.kim/blog/2017/10/27/KL_divergence.html)

<br>

## Bioinformatics
Review of Statistical Learning Methods in Integrated Omics Studies (An Integrated Information Science) by Irene Sui Lan Zeng and Thomas Lumley: [Paper](https://journals.sagepub.com/doi/pdf/10.1177/1177932218759292)

Dimension reduction techniques for the integrative analysis of multi-omics data by Chen Meng, et. al.: [Paper](https://academic.oup.com/bib/article/17/4/628/2240645)

Chapter 11: Genome-Wide Association Studies by William S. Bush and Jason H. Moore: [Paper](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002822)

Multi-Omics Factor Analysisâ€”a framework for unsupervised integration of multi-omics data sets by Ricard Argelaguet et.al.:[Paper](https://www.embopress.org/doi/full/10.15252/msb.20178124)

DIABLO: an integrative approach for identifying key molecular drivers from multi-omic assays by Amrit Singh et.al.:[Paper](https://doi.org/10.1093/bioinformatics/bty1054)

Why do we use mice for many experiments? [link](https://www.livescience.com/32860-why-do-medical-researchers-use-mice.html)

About Electronic Health Care Records. [link](https://www.businessinsider.com/electronic-health-records-benefits-challenges)

Find mapping -> From genome-wide associations to candidate causal variants by statistical fine-mapping by Daniel J. Schaid et.al.: [Paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6050137/)

Make improvements in Electronic health records (EHR) -> High-fidelity phenotyping: richness and freedom from bias by George Hripcsak and David J Albers: [Paper](https://academic.oup.com/jamia/article/25/3/289/4484121?login=true)

Multi-scale inference ofo genetic trait architecture using biologically annotated neural networks by Pinar Demetci et.al.: [Paper](https://www.biorxiv.org/content/10.1101/2020.07.02.184465v2)

<br>

## Machine Learning
Nice Intro-ANN, CNN, and RNN: [link](https://www.analyticsvidhya.com/blog/2020/02/cnn-vs-rnn-vs-mlp-analyzing-3-types-of-neural-networks-in-deep-learning/)

Love this BLOG-MachineCurve by Chris: [link](https://www.machinecurve.com/index.php/2019/07/18/can-neural-networks-approximate-mathematical-functions/)
<br/>[link1](https://www.machinecurve.com/index.php/2019/07/27/how-to-create-a-basic-mlp-classifier-with-the-keras-sequential-api/) -> MLP keras and tensorflow example
<br/>[link2](https://www.machinecurve.com/index.php/2018/12/07/convolutional-neural-networks-and-their-components-for-computer-vision/) -> CNN (Convolutional layers, pooling layers, fully connected layers)
<br/>[link3](https://www.machinecurve.com/index.php/2019/09/17/how-to-create-a-cnn-classifier-with-keras/) -> CNN keras and tensorflow example

towardsdatascience: [link](https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9) -> Here, specifically, it talks about **batch size v.s. epoch v.s. number of batches (iterations)***
<br/>[link1](https://towardsdatascience.com/deep-learnings-mathematics-f52b3c4d2576)&emsp;[link2](https://towardsdatascience.com/https-medium-com-piotr-skalski92-deep-dive-into-deep-networks-math-17660bc376ba) -> math behind Deep Learning step by step
<br/>[link3](https://towardsdatascience.com/recurrent-neural-networks-b7719b362c65) -> RNN
<br/>[link4](https://towardsdatascience.com/convolutional-neural-networks-mathematics-1beb3e6447c0) -> CNN

freeCodeCamp: [link](https://www.freecodecamp.org/news/connections-between-deep-learning-physics-and-pure-mathematics-part-i-947abeb3a5dd/) -> Here, specifically, it talks about the ***relationship between math and neural networks*** with an example

AnalyticsVidhya: [link](https://www.analyticsvidhya.com/blog/2020/01/fundamentals-deep-learning-activation-functions-when-to-use-them/#:~:text=The%20main%20advantage%20of%20using,neurons%20at%20the%20same%20time.&text=Due%20to%20this%20reason%2C%20during,neurons%20which%20never%20get%20activated.) -> Here, specifically, it talks about the **activation functions** for the layers.
<br/>[link1](https://www.analyticsvidhya.com/blog/2017/01/introduction-to-reinforcement-learning-implementation/) -> RL

Stanford Deep Learning CS 230: [link](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks) -> CNN and RNN (Super nice cheatsheets!!!)

Word2Vec by *The Coding Train*: [link](https://www.youtube.com/watch?v=mI23bDF0VRI&t=671s&ab_channel=TheCodingTrain)

Reinforcement Learning by **deepsense.ai** blog: [link](https://deepsense.ai/what-is-reinforcement-learning-the-complete-guide/)

Good summary of Reinforcement Learning by SmartLab AI: [link](https://medium.com/@SmartLabAI/reinforcement-learning-algorithms-an-intuitive-overview-904e2dff5bbc)

Self driving cab using RL by learndatasci: [link](https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/)

Pytorch Intro in Korean: [link](https://tutorials.pytorch.kr/beginner/deep_learning_60min_blitz.html) - original [link](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) 

Good explanation of logistic regression for classification problems by Christoph Molnar: [link](https://christophm.github.io/interpretable-ml-book/logistic.html)

Hyperparameters optimization for Deep Learning and Early Stopping criteria by flydhub blog: [link](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/) => **conclusion for Hyp. opt.: Bayes sequential model based optimization is the BEST for DL** 
