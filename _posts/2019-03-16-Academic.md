---
layout: post
title: "Academic related ^^"
date: 2018-10-06
---
# For those who are interested in my song lists, try [this](https://yjkweon24.github.io/blog/2018/10/23/songs-that-i-love)

<br>

<br>

## Statistics 
Statistics is fun!

Here are the [consumer analysis article](https://data.quora.com/A-Robust-Statistical-Test-for-Ratio-Metrics) co-written by one of my previous GSIs: Johnny and [2018 FIFA worldcup article](https://data.quora.com/FIFA-World-Cup-2018-seen-through-Quoras-numbers). 

This explains how stats can be applied into the real world problems! ^^

KL Divergence in Korean by Skywalk blog: [Link](https://hyunw.kim/blog/2017/10/27/KL_divergence.html)

<br>

## Bioinformatics
Review of Statistical Learning Methods in Integrated Omics Studies (An Integrated Information Science) by Irene Sui Lan Zeng and Thomas Lumley: [Paper](https://journals.sagepub.com/doi/pdf/10.1177/1177932218759292)

Dimension reduction techniques for the integrative analysis of multi-omics data by Chen Meng, et. al.: [Paper](https://academic.oup.com/bib/article/17/4/628/2240645)

Chapter 11: Genome-Wide Association Studies by William S. Bush and Jason H. Moore: [Paper](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002822)

Multi-Omics Factor Analysis—a framework for unsupervised integration of multi-omics data sets by Ricard Argelaguet et.al.:[Paper](https://www.embopress.org/doi/full/10.15252/msb.20178124)

DIABLO: an integrative approach for identifying key molecular drivers from multi-omic assays by Amrit Singh et.al.:[Paper](https://doi.org/10.1093/bioinformatics/bty1054)

Why do we use mice for many experiments? [link](https://www.livescience.com/32860-why-do-medical-researchers-use-mice.html)

About Electronic Health Care Records. [link](https://www.businessinsider.com/electronic-health-records-benefits-challenges)

Find mapping -> From genome-wide associations to candidate causal variants by statistical fine-mapping by Daniel J. Schaid et.al.: [Paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6050137/)

Make improvements in Electronic health records (EHR) -> High-fidelity phenotyping: richness and freedom from bias by George Hripcsak and David J Albers: [Paper](https://academic.oup.com/jamia/article/25/3/289/4484121?login=true)

Multi-scale inference ofo genetic trait architecture using biologically annotated neural networks by Pinar Demetci et.al.: [Paper](https://www.biorxiv.org/content/10.1101/2020.07.02.184465v2)

Deep Convolutional Neural Networks for Breast Cancer Histology Image Analysis by Alexander Rakhlin et.al.: [Paper](https://arxiv.org/abs/1802.00752)

A unified framework for cross-population trait prediction by leveraging the genetic correlation of polygenic traits by Mingxuan Cai et.al.: [Paper](https://doi.org/10.1016/j.ajhg.2021.03.002)

Inferring multimodal latent topics from electronic health records by Yue Li et.al.: [Paper](https://www.nature.com/articles/s41467-020-16378-3)

Going to Bat(s) for Studies of Disease Tolerance by Judith N Mandl et.al.: [Paper](https://www.frontiersin.org/articles/10.3389/fimmu.2018.02112/full) ~~ COVID 19 related???

Single-cell epigenomic analyses implicate candidate causal variants at inherited risk loci for Alzheimer’s and Parkinson’s diseases: [Paper](https://www.nature.com/articles/s41588-020-00721-x) ~~ Power of single cell analysis

Joint probabilistic modeling of single-cell multi-omic data with totalVI by Adam Gayoso et.al.: [Paper](https://www.nature.com/articles/s41592-020-01050-x) ~~ joint analysis of CITE seq data

Applications of machine learning in drug discovery and development by Jessica Vamathevan et.al.: [Paper](https://www.nature.com/articles/s41573-019-0024-5) ~ Introduce different methodologies for each step in drug discovery

Modeling polypharmacy side effects with graph convolutional networks by Marinka Zitnik et.al.: [Paper](https://academic.oup.com/bioinformatics/article/34/13/i457/5045770)

<br>

## For Project on AI Drug Design (2021 Fall)

Reconstructing SARS-CoV-2 response signaling and regulatory networks by Jun Ding et.al.: [Paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7574259/) ~ using network and pathway with integration of previously identified datasets+analysis, let's make drug design work!

iDREM: Interactive visualization of dynamic regulatory networks by Jun Ding et.al.: [Paper](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006019) ~ integration of time series proteomics, epigenomics, scRNA-seq, interactive visualization leads higher accuracy of a model.

Cellar: Interactive single cell data annotation tool by Euxhen Hasanaj et.al.: [Paper](https://www.biorxiv.org/content/10.1101/2021.03.19.436162v1.abstract) ~ explain the UI web server for single cell data annotation tool from preprocessing to all the way to analysis. 1. **Preprocessing** - i.e. based on dispersion and max expression value 2. **Dimensionality reduction** - i.e. linear (PCA, truncated SVD) & non-linear (diffusion map, UMAP, multidimensional scaling, isomap) 3. **Clustering** - i.e. unsupervised (Leiden, k-means, k-medoids, spectral clustering, agglomerative clustering) & semi-supervised (seeded k-means, constrained k-means) 4. **Cell type assignment** - i.e. co-expression based cell coloring 5. **Cell type assignment using label transfer** - i.e. scanpy ingest, singleR

AI drug design video: 
- [video 1](https://www.youtube.com/watch?v=xDMzOUUnNzw) - Quantitative structure-activity relatioinship. 
- [video 2](https://www.youtube.com/watch?v=aqMRrRS_0JY) - AI driven drug discovery using relationships between proteins, drugs, diseases and metabolites with network prediction like what Mummichog and Piumet do. 
- [video 3](https://www.youtube.com/watch?v=eRXqD-7FANg) - use AI to design drugs faster and cheaper learning disease targets better. 
- [video 4](https://www.youtube.com/watch?v=hY9Bc3mtphs) - Drug discovery using [ChemGAN](https://github.com/mostafachatillon/ChemGAN-challenge) speeding up 8-12 years conventional one drug discovery by trying and choosing molecules that are most likely to have desired properties [*a note from Siraj*](https://github.com/llSourcell/AI_for_healthcare/blob/master/Healthcare%20Drug%20Discovery.ipynb) - explains conventional drug discovery process and show ML history on it (i.e. RNN, CNN, GAN) and real demo on python using Tensorflow

Probabilisitc graphical model: 
- [video 1](https://www.youtube.com/watch?v=DEHqIxX1Kq4) - show a good example of directional acyclic causal networks with demo using [**pgmpy**](https://pgmpy.org/) python lib: Bayesian network (Markov "since it is explained by your immediate neighbor") and thus every edge is conditional probabilistic (i.e. conditional probability distribution when it is Markov -> P(node val|parent's node val)).    
- [video 2](https://www.youtube.com/watch?v=zCWRTKnOYYg) - encode joint distribution by conditional independence in directed acyclic Bayesian networks (approaches for inference: 1. enumeration 2. variable elimination - elimination order can change computational cost 3. belief propagation).
- [video 3](https://www.youtube.com/watch?v=iBQkZdPHlCs) - undirected graphical models: Markov random fields (edge: potential function between variables) and convert Bayesian networks as MRF (parametrication is NOT unique) but lose marginal independce of parents.   
- [towards data science blog](https://towardsdatascience.com/introduction-to-probabilistic-graphical-models-b8e0bf459812) - Definition of PGM, directed graphical model (bayesian network)+3 rules of d-separation (1. if there is no unidirectional path between them 2. another set of nodes block any unidirectional path between them 3. a node which has two or more parents or its descendants break d-separation of their parents), undirected graphical model (markov random field - may contain cycles unlike BN thus it can describe a different set of dependency relationships than BN; yet, it is not a superset of DGM since some relatinoships such as causal can only be described by DGM. Undirected edge reprents joint probabilities of cliques. Pairwise+local+global markov properties), conversion of BN and MRF (not easy as independence relationships are diff. Moralization to convert BN to MRF. Triangulation to convert MRF to BN), and inference (variable elimination - exact inference algorithm but it can be computationally intractible for large BN)+parameter estimation in PGM.
 
<br>

## For Project on [MetaboAnalyst](https://www.metaboanalyst.ca/home.xhtml) - Metab (2021 Summer)

Predicting Network Activity from High Throughput Metabolomics by Shuzhao Li et.al.: [Paper](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003123) ~ mummichog algorithm (using metabolic pathways and networks to predict functional acitivity without priori identifications of metabolites using biological activity) introduction with a few applications

MetaboAnalyst 4.0: towards more transparent and integrative metabolomics analysis by Jasmine Chong et.al.: [Paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6030889/) ~ update 1. R-command tracking+display and companion [metaboAnalystR](#mar) package (transparency, reproducibility, flexibility), 2. MS peaks to pathways to predict pathway activity from untargeted MS using mummichog, 3. biomarker meta-analysis thru combination of multiple metabolomics data, and 4. network explorer for integrative analysis of metabolomics, metagenomics, transcriptomics *5. knowledgebase updates (compound database, pathway libraries, metabolite sets)*

MetaboAnalyst 5.0: narrowing the gap between raw spectra and functional insights by Zhiqiang Pang et.al.: [Paper](https://academic.oup.com/nar/advance-article/doi/10.1093/nar/gkab382/6279832) ~ update 1. LC-MS spectra processing module (automated paramter optimization and resumable analysis) with interactive plots, 2. functional analysis module (select any peak groups of interests and evaluate enrichment of potential functions), and 3. functional meta-analysis module (combine multiple global metabolomics datasets) by pathway level integration (different samples) or pooling peaks (same samples)

Revealing disease-associated pathways by network integration of untargeted metabolomics by Leila Pirhaji et.al: [Paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5209295/)

<a name="mar"></a>
MetaboAnalystR 2.0: From Raw Spectra to Biological Insights by Jasmine Chong et.al.: [Paper](https://www.mdpi.com/2218-1989/9/3/57) ~ update 1. raw spectral processing and 2. mummichog algorithm. Show two case studies

MetaboAnalystR 3.0: Toward an Optimized Workflow for Global Metabolomics by Zhiqiang Pang et.al.: [Paper](https://www.mdpi.com/2218-1989/10/5/186) ~ update 1. efficient parameter optimization, 2. automated batch effect correction, and 3. more accurate pathway activity prediction with retention time + updated pathway libraries => faster computationally and more biologically meaningful interpretations

  
<br>

## Machine Learning
Nice Intro-ANN, CNN, and RNN: [link](https://www.analyticsvidhya.com/blog/2020/02/cnn-vs-rnn-vs-mlp-analyzing-3-types-of-neural-networks-in-deep-learning/)

Love this BLOG-MachineCurve by Chris: [link](https://www.machinecurve.com/index.php/2019/07/18/can-neural-networks-approximate-mathematical-functions/)
<br/>[link1](https://www.machinecurve.com/index.php/2019/07/27/how-to-create-a-basic-mlp-classifier-with-the-keras-sequential-api/) -> MLP keras and tensorflow example
<br/>[link2](https://www.machinecurve.com/index.php/2018/12/07/convolutional-neural-networks-and-their-components-for-computer-vision/) -> CNN (Convolutional layers, pooling layers, fully connected layers)
<br/>[link3](https://www.machinecurve.com/index.php/2019/09/17/how-to-create-a-cnn-classifier-with-keras/) -> CNN keras and tensorflow example

towardsdatascience: [link](https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9) -> Here, specifically, it talks about **batch size v.s. epoch v.s. number of batches (iterations)***
<br/>[link1](https://towardsdatascience.com/deep-learnings-mathematics-f52b3c4d2576)&emsp;[link2](https://towardsdatascience.com/https-medium-com-piotr-skalski92-deep-dive-into-deep-networks-math-17660bc376ba) -> math behind Deep Learning step by step
<br/>[link3](https://towardsdatascience.com/recurrent-neural-networks-b7719b362c65) -> RNN
<br/>[link4](https://towardsdatascience.com/convolutional-neural-networks-mathematics-1beb3e6447c0) -> CNN

freeCodeCamp: [link](https://www.freecodecamp.org/news/connections-between-deep-learning-physics-and-pure-mathematics-part-i-947abeb3a5dd/) -> Here, specifically, it talks about the ***relationship between math and neural networks*** with an example

AnalyticsVidhya: [link](https://www.analyticsvidhya.com/blog/2020/01/fundamentals-deep-learning-activation-functions-when-to-use-them/#:~:text=The%20main%20advantage%20of%20using,neurons%20at%20the%20same%20time.&text=Due%20to%20this%20reason%2C%20during,neurons%20which%20never%20get%20activated.) -> Here, specifically, it talks about the **activation functions** for the layers.
<br/>[link1](https://www.analyticsvidhya.com/blog/2017/01/introduction-to-reinforcement-learning-implementation/) -> RL

Stanford Deep Learning CS 230: [link](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks) -> CNN and RNN (Super nice cheatsheets!!!)

Word2Vec by *The Coding Train*: [link](https://www.youtube.com/watch?v=mI23bDF0VRI&t=671s&ab_channel=TheCodingTrain)

Reinforcement Learning by **deepsense.ai** blog: [link](https://deepsense.ai/what-is-reinforcement-learning-the-complete-guide/)

Good summary of Reinforcement Learning by SmartLab AI: [link](https://medium.com/@SmartLabAI/reinforcement-learning-algorithms-an-intuitive-overview-904e2dff5bbc)

Self driving cab using RL by learndatasci: [link](https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/)

Pytorch Intro in Korean: [link](https://tutorials.pytorch.kr/beginner/deep_learning_60min_blitz.html) - original [link](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) 

Good explanation of logistic regression for classification problems by Christoph Molnar: [link](https://christophm.github.io/interpretable-ml-book/logistic.html)

Hyperparameters optimization for Deep Learning and Early Stopping criteria by flydhub blog: [link](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/) => **conclusion for Hyp. opt.: Bayes sequential model based optimization is the BEST for DL** 

Variational Autoencoder explanation by **Arxiv Insights**: [link](https://youtu.be/9zKuYvjFFS8)

GPU CUDA: 
- [video 1](https://www.youtube.com/watch?v=IzU4AVcMFys) - NVIDIA CUDA intro
- [video 2](https://www.youtube.com/watch?v=6stDhEA0wFQ) - Deep learning using gpu soft architecture API (CUDA) on pytorch example for parallel computing
- [video 3](https://www.youtube.com/watch?v=1cHx1baKqq0) - GPU programming with CUDA in C++

Graph convolutional network: [link1](https://neptune.ai/blog/graph-neural-network-and-some-of-gnn-applications)
<br/>[link2](https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780)
